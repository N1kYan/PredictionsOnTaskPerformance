\documentclass[../main/main.tex]{subfiles}

% Put everything that shall appear in the introduction
% inside this document environment.
\begin{document}
	The question of how to predict peoples performance on a task has been of great interest in the psychology literature. To be able to make qualified statements about this ability, one has to define it first.
	This can be achieved by the framework of \textit{metacognition} including the terms \textit{metacognitive sensitivity}, \textit{metacognitive bias} and \textit{metacoognitive efficiency} [x].\\
	The first is used to express how good a subject is at differing between his or her own correct and incorrect answers. A useful initial approach is the $2x2$ confidence-accuracy table, labeled "type 2 SDT table" by [x] that is the equivalent of the usual "type-1" SDT table [x] applied to the \textit{metacognition} framework. Common measures of the association between the rows and the colums of the table in the type-1 case are the $\phi$-correlation [x] and the Goodman-Kruskall gamma coefficient $G$ [x]. It is well known that both measurements are affected by (metacognitive?) bias [x], and [x] showed that this also holds for the type-2 application of the measurements.\\
	A standard way to remove the influence of the bias would be using $d'$ [x] which will be constant given different biases and also has several approaches to metacognitive sensitivity [x]. But type-2 $d'$ is also affected by changes in the metacognitive bias (HOW?)[x].\\
	One way to remove this issue is the use of non-parametric analysis, that does not make the equal-variance gaussian assumptions, e.g. ROC analysis [x], that can be applied to type-2 data.\\
	A further complication for using the above methods to measure metacognitive sensitivity is the fact that all these measures are affected by the task performance (HOW?) [x]. This can be adressed by excplicitly modeling the connection between a subject's performance and metacognition. The meta-$d'$ measure [x] makes use of the fact that given gaussian variance assumptions (?) at type-1 level, the shapes of the type-2 distributions are known even if they are not themselves gaussian (WHY ?). Therefore the optimal type-2 performance is constrained by one's type-1 performance. E.g. given a particular type-1 variance structure and bias, the form of the type-2 ROC is completely determined. So, given a subject's actual type-2 performance, one could obtain the underlying type-1 sensitivity, labeled meta-$d'$ [x], that is robust to changes in the bias and recovers simulated changes in metacognitive sensitivity. For a metacognitively ideal observer, meta-$d'$ should be equal to $d'$. To measure this ideality, [] defined \textit{metacognitive efficiency} as meta-$d'/d'$, or by the more stable variants meta-$d'-d'$ or $log$meta-$d'/d'$. However, this measurement is unable to discriminate between different causes of a change in metacognitive efficience. E.g. trial-to-trial variability in the placement of confidence criteria results in decreasing efficiency as well as additional noise in the evidence used to make the confidence rating. A similar bias-free approach to model metacogntivie accuracy ist the \textit{Stochastic Detection and Retrieval Model (SDRM)} which we do not want to cover here.\\
	A somewhat different approach uses so-called \textit{one-shot} discrepancy measures to quantify metacognition. A general confidence rating (e.g. asked before the trial) is compared to the actual performance on a variety of tasks, but it should be clear from the above (WHY ?) that using a single rating of performance will not result in a good distinction between the bias and the sensitivity, nor will it enable to measure the efficiency. In contrasst, collecting trial-by-trial measures of performance and metacognitive judgements allows to get a picture of an individuals bias, sensitivity and efficiency.\\
	To get a different view-point on the domain, one could formalize metacognitive confidence as a probability judgement directed towards one's own actions.
	\\
\begin{itemize}

	\item Metacognitive confidence can be formalized as a \textbf{probability judgement} directed towards one's own actions.
	\item [] \begin{itemize}
			\item Metacognition has a normative interpretation as the accuracy of a probability judgement about one's own performance.
			\item Advantage of this framework: Meaningful measure of bias can be elicited.
			\item "Probability Score": $PS = (f - c)^2$
			\item $f$: probability rating
			\item $c$: actual occurence (c=1/0 for binary events)
			\item "Brier Score": Mean value of the PS averaged across estimates.
			\item Brier score is analogous to $\phi$.
			\item Can be decomposed into: $PS = O + C -R$
			\item $O$: "Outcome index", reflecting the variance of the outcome event $c$
			\item $C$: "Calibration", the goodness of fit between probability assessments and the corresponding proportion of correct responses. Quantifies the discrepancy between the mean performance level in a category (e.g. $60\%$) and its associated rating (e.g. $80\%$).
			\item $R$: "Resolution, the variance of the probability assessments. Measuring the extent to which correct and incorrect answers are assigned to different probability categorices (Is substracted; larger variance is better).
		\end{itemize}
	
\end{itemize}

\end{document}