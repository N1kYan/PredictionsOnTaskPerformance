\documentclass[../main/main.tex]{subfiles}

% Put everything that shall appear in the introduction
% inside this document environment.
\begin{document}
	The question of how to predict peoples performance on a task has been of great interest in the psychology literature. To be able to make qualified statements about this ability, one has to define it first.
	This can be achieved by the framework of \textit{metacognition} including the terms \textit{metacognitive sensitivity}, \textit{metacognitive bias} and \textit{metacoognitive efficiency} [x] that will be explained during this first section.\\
	\textit{Metacognitive sensitivity} is used to express how good a subject is at differing between his or her own correct and incorrect answers. For example, imagine a classical experiment from \textit{signal detection theory (SDT)} where the subjects task is to rate a stimulus to come from a class A or a distinct class B. Poor metacognitive sensitivity would result in a bad distinction between the possible origins, even though the classes are easy to separate for an average observer. A useful initial approach to quantify [MEASURE ?] \textit{metacognitive sensitivity} is the $2x2$ confidence-accuracy table, labeled \textit{type 2 SDT table} by [x] that is the equivalent of the usual \textit{type-1 SDT table} [x], shown in the upper part from figure \ref{fig:tables}, applied to the \textit{metacognition} framework. The resulting table is displayed in the lower part of \ref{fig:tables}. The usual SDT measurementents of the association between the rows and the colums of the table in the type-1 case is the \textit{$\phi$-correlation} [x] and the \textit{Goodman-Kruskall gamma coefficient $G$} [x]. Imagine a subject reporting a subjective confidence for multiple trials of the former example stored in a vector, e.g $(A, B, B, A)$, and the vecotr of the actual correct classifications $(A, B, A, B)$. If we encode $A=1$ and $B=0$, the $\phi$-correlation is the  \textit{Pearson r-correlation} between both vector. The advante of using $G$ instead is the abundance of any distributional assumptions on the data and the possibility to easily extend the measurement to a confidence rating scale (e.g. from 0 to 100), rather than a binary encoding (e.g. 0/1). Nevertheless it is well known that both measurements are affected by bias [x], and [x] showed that this also holds for the type-2 application of these measurements.
	\begin{figure}[h]
		\centering
		\captionsetup{justification=centering}
		\label{fig:tables}
		\includegraphics[width=0.7\textwidth]{../assets/type1_sdt_table.png}
		\includegraphics[width=0.7\textwidth]{../assets/type2_sdt_table.png}
		\caption{The type-1 and type-2 2x2 SDT-tables [TODO: REMOVE TABLE 3.1 / TABLE 3.2 CAPTIONS FROM IMAGES][TODO: MAKE OWN PLOT!].} 
	\end{figure}\\
	A standard way to remove the influence of the bias in classic SDT is using $d'$ [x] which will be constant given different biases and also has several approaches to metacognitive sensitivity, e.g. [x] defined type-2 $d'$ as
	\begin{displaymath}
		d' = z(H2) - z(FA2)
	\end{displaymath}
	A visualisation of this measurement is shown in figure \ref{fig:d_dash}.
	\begin{figure}[h]
		\centering
		\captionsetup{justification=centering}
		\label{fig:d_dash}
		\includegraphics[width=0.6\textwidth]{../assets/d_dash.png}
		\caption{The d' measurement, calculated as the difference\\ between the (inverse of) the hit rate (HR) and the fals alarm rate (FA). [TODO: MAKE OWN PLOT!]} 
	\end{figure}
	Despite this advantage, $d'$ can not easily applied to the type-2 data, because it includes assumptions of gaussian distributions with equal variance, which is very unlikely to be the case in type-2 data, as shown by [x]. Experiments of these authors shoed that it is indeed affected by changes in the metacognitive bias.\\
	One way to remove this issue is the use of non-parametric analysis, that does not make these assumptions, e.g. the \textit{Receiver operating characteristic (ROC)} analysis [x] in classic SDT. This approach can be applied to type-2 data and an example is given in figure \ref{fig:roc}\\
	\begin{figure}[h]
		\centering
		\captionsetup{justification=centering}
		\label{fig:roc}
		\includegraphics[width=0.6\textwidth]{../assets/type1_roc.png}
		\caption{ROC analysis. [TODO: MAKE OWN PLOT!][THIS EXAMPLE IS FOR TYPE-1?]} 
	\end{figure}
	A further complication for using the above methods to measure metacognitive sensitivity is the fact that all these measures are affected by the task performance (HOW?) [x]. This can be adressed by excplicitly modeling the connection between a subject's performance and metacognition in a model-based approach. The \textit{meta-$d'$} measure [x] makes use of the fact that given gaussian variance assumptions (?) at type-1 level, the shapes of the type-2 distributions are known even if they are not themselves gaussian (WHY?). Therefore the optimal type-2 performance is constrained by one's type-1 performance. E.g. given a particular type-1 variance structure and bias, the form of the type-2 ROC is completely determined. So, given a subject's actual type-2 performance, one could obtain the underlying type-1 sensitivity, labeled meta-$d'$ [x], that is robust to changes in the bias and recovers simulated changes in metacognitive sensitivity. For a metacognitively ideal observer, meta-$d'$ should be equal to $d'$. To measure this ideality, [] defined \textit{metacognitive efficiency} as meta-$d'/d'$, or by the more stable variants meta-$d'-d'$ or $log$meta-$d'/d'$. However, this measurement is unable to discriminate between different causes of a change in metacognitive efficience. E.g. trial-to-trial variability in the placement of confidence criteria results in decreasing efficiency as well as additional noise in the evidence used to make the confidence rating. A similar bias-free approach to model metacogntivie accuracy ist the \textit{Stochastic Detection and Retrieval Model (SDRM)} which we do not want to cover here.\\
	A somewhat different approach uses so-called \textit{one-shot} discrepancy measures to quantify metacognition. A general confidence rating (e.g. asked before the trial) is compared to the actual performance on a variety of tasks, but it should be clear from the above (WHY?) that using a single rating of performance will not result in a good distinction between the bias and the sensitivity, nor will it enable to measure the efficiency. In contrasst, collecting trial-by-trial measures of performance and metacognitive judgements allows to get a picture of an individuals bias, sensitivity and efficiency.\\
	To get a different view-point on the domain, one could formalize metacognitive confidence as the ability to make good probability judgements directed towards the accuracy of one's own actions.
	
	\newpage
	\subsection{Formalizing metacognition as probability judgements}
	
	\textit{Metacognition} has a normative interpretation as the accuracy of a probability judgement about one's own performance and one advantage is the possibility to elicit a meaningful measure of the bias. A lot of literature is a availabe on how to measure this accuracy, but in the following we want to focus on one of them, called the \textit{Brier Score}. To define this score, [x] first defined the \textit{Probability Score (PS)} as the squared difference between a probability rating $f$ for an event, and it's actual occurence $c$ (0 or 1 for binary events):
	\begin{displaymath}
			PS = (f - c)^2
	\end{displaymath}
	The \textit{Brier Score (BS)} can then be defined as the mean value of the PS averaged across all estimates:
	\begin{displaymath}
			BS = \frac{1}{N}\sum_i(f_i - c_i)^2
	\end{displaymath}
	This score is the equivalent of the $\phi$ measurement explained above and can be decomposed, shown by [x], by:
	\begin{displaymath}
		BS = O + C - R
	\end{displaymath}
	[TODO: EXPLAIN FURTHER!]
	where $O$ is the \textit{Outcome index}, reflecting the variance of the outcome event $c$. The \textit{Calibration} expresses the goodness of fit between the probability assessments and the corresponding proportion of correct responses. It quantifies the discrepancy between the mean performance level in categorcy (e.g. $60\%$) and its associated rating (e.g. $80\%$). Last, the \textit{Resolution} $R$ encodes the variance of the probability assessments, measuring the extent to which correct and incorrect answers are assigned to different probability categories (EXPLAIN THESE FURTHER).\\
	The next chapter gives an overview on how we measured the brier score of several subjects for different tasks, before we present the results of our measurements and finally come to a conclusion on our atttempt to measure metacognition.
	

\end{document}